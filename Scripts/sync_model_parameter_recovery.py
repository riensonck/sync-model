# -*- coding: utf-8 -*-

"""
Author: Rien Sonck
Date: 2020-06-28
Description: This file aims to recover the parameters used to generate simulated data.  
"""
######################
# Importing packages #
######################
from Sync_Model import model_sim
from scipy.optimize import differential_evolution
import pandas as pd
from scipy import ndimage
import numpy as np
import time


def new_goal_func(x, *args):
    ######################################
    # Value Extraction and Initalization #
    ######################################
    """ 
    function that returns the error of the goal function based on previously generated 
    simulated data files by Sync_Model_Simulations.py

    Parameters
    ----------
    x    : integer
           this value lies in-between the specified bounds, and will be generated by the differential evolution algorithm. 
    args : tuple
           any additional fixed model parameters and other variables needed to completely specify the objective function.
    """ 
    gd = args[0]              # gamma distance model parameter
    #thres = args[1]           # mfc frequency model parameter
    target_file = args[1]     # target file
    squared_err = []
    mfc, thres = x[0], x[1]
    ####################
    # Reading in data #
    ###################
    # reading in the target data
    pd_targetData = pd.read_csv(target_file)
    ################################
    # Generating model simulations #
    ################################
    pd_data = model_sim(Threshold = thres, drift = gd, theta_freq = mfc, save_behavioral = False, return_dataframe = True)
    ###################################
    # Calculating RT Shape difference #
    ###################################
    accuracy = pd_data['accuracy'].unique() 
    for acc in accuracy: 
        # extracting RTs
        rt_sim = pd_data.loc[pd_data['accuracy'] == acc, 'rt'].values               # simulated RTs
        rt_target = pd_targetData.loc[pd_targetData['accuracy'] == acc, 'rt'].values    # target RTs
        # creating bins
        bins = np.arange(0, 700.1, 25)
        # getting histogram data
        heights_sim, bins = np.histogram(rt_sim, bins=bins)
        heights_target, bins = np.histogram(rt_target, bins=bins)
        # calculating the difference
        diff = heights_target - heights_sim
        # calculating the squared error
        err = sum(diff**2)
        squared_err.append(err)

    ###################################
    # Calculating RT Peak difference  #
    ###################################
    # applying kernels to the error and correct RT distributions
    # getting the right sigma for smoothing
    cor_indices_target, err_indices_target = [], []
    cor_indices_sim, err_indices_sim = [], []
    bins = np.arange(0, 1000, 10)

    sigma_cor = 5
    sigma_err = 5
    # this while loop will keep reducing the sigma until we can recover the second peak
    while len(cor_indices_target) < 1 or len(err_indices_target) < 1:
        RT_hist_list_target = RT_distribution_smoothing(pd_targetData, bins, sigma_err, sigma_cor)
        # finding where in the bins the peaks and troughs happen and mark it 
        time_step_change_target = np.diff(np.sign(np.diff(RT_hist_list_target)))
        # extracting the index of the peak and trough bins based on the marker
        cor_indices_target = np.where((time_step_change_target[1]!= 0) & (time_step_change_target[1] != 1))[0]
        err_indices_target = np.where((time_step_change_target[0] != 0) & (time_step_change_target[0] != 1))[0] 
        if len(cor_indices_target) < 1: 
            sigma_cor = sigma_cor - 1
        if len(err_indices_target) < 1:
            sigma_err = sigma_err - 1


    sigma_cor = 5
    sigma_err = 5
    while len(cor_indices_sim) < 1 or len(err_indices_sim) < 1:
        RT_hist_list_sim = RT_distribution_smoothing(pd_data, bins, sigma_err, sigma_cor)
        # finding where in the bins the peaks and troughs happen and mark it 
        time_step_change_sim = np.diff(np.sign(np.diff(RT_hist_list_sim)))
        # extracting the index of the peak and trough bins based on the marker
        cor_indices_sim = np.where((time_step_change_sim[1]!= 0) & (time_step_change_sim[1] != 1))[0]
        err_indices_sim = np.where((time_step_change_sim[0] != 0) & (time_step_change_sim[0] != 1))[0]
        if len(cor_indices_sim) < 1: 
            sigma_cor = sigma_cor - 1
        if len(err_indices_sim) < 1:
            sigma_err = sigma_err - 1

    # extracting the peaks and trough bin value
    peaks_troughs_err_target = RT_hist_list_target[0][err_indices_target]
    peaks_troughs_cor_target = RT_hist_list_target[1][cor_indices_target]
    peaks_troughs_err_sim = RT_hist_list_sim[0][err_indices_sim]
    peaks_troughs_cor_sim = RT_hist_list_sim[1][cor_indices_sim]
    # calculate the relative peak height
    #relative_height_cor_target = peaks_troughs_cor_target[1] / peaks_troughs_cor_target[0]
    #relative_height_err_target = peaks_troughs_err_target[1] / peaks_troughs_err_target[0]
    #relative_height_cor_sim = peaks_troughs_cor_sim[1] / peaks_troughs_cor_sim[0] 
    #relative_height_err_sim = peaks_troughs_err_sim[1] / peaks_troughs_err_sim[0]
    relative_height_target = peaks_troughs_err_target[0] / peaks_troughs_cor_target[0]
    relative_height_sim = peaks_troughs_err_sim[0] / peaks_troughs_cor_sim[0]
    # error
    #peak_error = np.abs(relative_height_cor_sim - relative_height_cor_target) + np.abs(relative_height_err_sim - relative_height_err_target)
    peak_error = np.abs(relative_height_target - relative_height_sim)


    # squared_err[1] is error, squared_err[0] is correct
    # peak_error * 10**6 -
    error = squared_err[1] + squared_err[0] + (peak_error * 10**4)
    print("mfc: {0}, thres: {1}, gd: {2}, error: {3}".format(mfc, thres, gd, error))
    return error

def RT_distribution_smoothing(pd_data, bins, sigma_err, sigma_cor):
    """ 
    Function that applies the difference kernel and then a Gaussian smoothing kernel to the error 
    and correct RT distributions corresponding to each MFC frequency in the model.  

    Parameters
    ----------
    pd_data    : pandas dataframe 
                 dataframe containing the data
    bins       : numpy array
                 array containing the bins for the histograms
    sigma      : integer
                 smoothing of the Gaussian kernel
    """ 
    accuracy = [0, 1]
    thetas_hist_list = []
    theta_hist = np.zeros(shape=[2, 1, len(bins)-1])
    ###################
    # Reading in data #
    ###################
    # creating histograms
    theta_hist[0, :] = np.histogram(pd_data.loc[pd_data['accuracy']== 0, 'rt'].values, bins=bins, normed = True)[0] # error histograms
    theta_hist[1, :] = np.histogram(pd_data.loc[pd_data['accuracy']== 1, 'rt'].values, bins=bins, normed = True)[0] # correct histograms
    ###################################
    # Difference Kernel and Smoothing #
    ###################################
    # run difference kernel
    theta_histDiff_err = -np.array([theta_hist[0][0][bin_n] - (theta_hist[0][0][bin_n-1] + theta_hist[0][0][bin_n+1]).mean() for bin_n in np.arange(1, len(bins)-2)]).T
    theta_histDiff_cor = -np.array([theta_hist[1][0][bin_n] - (theta_hist[1][0][bin_n-1] + theta_hist[1][0][bin_n+1]).mean() for bin_n in np.arange(1, len(bins)-2)]).T
    # smooth
    theta_histDiffSmooth_err = ndimage.gaussian_filter1d(theta_histDiff_err, axis = 0, sigma = sigma_err)
    theta_histDiffSmooth_cor = ndimage.gaussian_filter1d(theta_histDiff_cor, axis = 0, sigma = sigma_cor)
    return (theta_histDiffSmooth_err, theta_histDiffSmooth_cor)


########################
# Value initialization #
########################
# path to the folder containing the target data
path = ''
mfc_freq_target = np.arange(8, 9, 1)
thres_target = np.arange(4 , 5, 1)
gds_target = np.arange(2, 3, 1)
# model parameters
bounds = [(3, 9), (1,5)]

results = []
for mfc in mfc_freq_target: 
  for gd in gds_target: 
    for thres in thres_target:
      target_file = '{0}Behavioral_Data_simulation_sub0_thetaFreq{1}.00Hz_thresh{2}_drift{3}.0.csv'.format(path, mfc, thres, gd)
      print(target_file)
      print("=======")
      args =(gd, target_file) 	# arguments that the sync_func function needs to run (gamma distance, MFC frequency value, target dataframe)
      #################
      # Model Fitting #
      #################
      t = time.time()
      result = differential_evolution(func=new_goal_func, bounds=bounds, args=args, workers = -1, popsize = 15, maxiter = 1000, updating = 'deferred', tol = 2, atol = 0)
      d = {'mfc': mfc, 'gd': gd, 'thres': thres, "mfc_result": result.x}
      data = pd.DataFrame(data=d)
      results.append(data)
      print("result: mfc = {0}, thres = {1}, mfc_result = {2}, thres_result = {3}\n".format(mfc, thres, result.x[0], result.x[1]))
      print('\ttime taken: %.2fmin' % ((time.time() - t) / 60.))
pd_results = pd.concat(results, axis=0, ignore_index=True)